## Hugging Face Transformers Tutorial (Winter '22) - Stanford Course
**[YouTube video course](https://youtu.be/b80by3Xk_A8?si=2Yee9XeMrtsjo8CG)**

This notebook will give an introduction to the Hugging Face Transformers Python library and some common patterns that you can use to take advantage of it. It is most useful for using or fine-tuning pretrained transformer models for your projects.

Hugging Face provides access to models (both the code that implements them and their pre-trained weights), model-specific tokenizers, as well as pipelines for common NLP tasks, and datasets and metrics in a separate datasets package. It has implementations in PyTorch, Tensorflow, and Flax (though we'll be using the PyTorch versions here!) 
