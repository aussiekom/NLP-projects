{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKB26q-4-X8r"
      },
      "source": [
        "# CS224N: Hugging Face Transformers Tutorial (Winter '22)\n",
        "\n",
        "This notebook will give an introduction to the Hugging Face Transformers Python library and some common patterns that you can use to take advantage of it. It is most useful for using or fine-tuning pretrained transformer models for your projects.\n",
        "\n",
        "\n",
        "Hugging Face provides access to models (both the code that implements them and their pre-trained weights), model-specific tokenizers, as well as pipelines for common NLP tasks, and datasets and metrics in a separate `datasets` package. It has implementations in PyTorch, Tensorflow, and Flax (though we'll be using the PyTorch versions here!)\n",
        "\n",
        "\n",
        "We're going to go through a few use cases:\n",
        "* Overview of Tokenizers and Models\n",
        "* Finetuning - for your own task. We'll use a sentiment-classification example.\n",
        "\n",
        "\n",
        "Chris spoke about a few main project types in last Thursday's lecture:\n",
        "1. Applying an existing pre-trained model to a new application or task and explore how to approach/solve it\n",
        "2. Implementing a new or complex neural architecture and demonstrate its performance on some data\n",
        "3. Analyzing the behavior of a model: how it represents linguistic knowledge or what kinds of phenomena it can handle or errors that it makes\n",
        "\n",
        "Of these, `transformers` will be the most help for 1. and for 3. (You also can use it to define your own model architectures, but it's a bit tricky and we won't be covering it here.)\n",
        "\n",
        "\n",
        "\n",
        "Here are additional resources introducing the library that were used to make this tutorial:\n",
        "\n",
        "* [Hugging Face Docs](https://huggingface.co/docs/transformers/index)\n",
        "  * Clear documentation\n",
        "  * Tutorials, walk-throughs, and example notebooks\n",
        "  * List of available models\n",
        "* [Hugging Face Course](https://huggingface.co/course/)\n",
        "* [Hugging Face O'Reilly Book](https://www.oreilly.com/library/view/natural-language-processing/9781098103231/)\n",
        "    * Students have FREE access through the Stanford Library!\n",
        "\n"
      ],
      "id": "sKB26q-4-X8r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9EhWoZef-X8u"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "id": "9EhWoZef-X8u"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q9th7mpc-X8v"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "import json\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def print_encoding(model_inputs, indent=4):\n",
        "    indent_str = \" \" * indent\n",
        "    print(\"{\")\n",
        "    for k, v in model_inputs.items():\n",
        "        print(indent_str + k + \":\")\n",
        "        print(indent_str + indent_str + str(v))\n",
        "    print(\"}\")"
      ],
      "id": "Q9th7mpc-X8v"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmXezUMg2idv"
      },
      "source": [
        "## Part 0: Common Pattern for using Hugging Face Transformers\n",
        "\n",
        "We're going to start off with a common usage pattern for Hugging Face Transformers, using the example of Sentiment Analysis.\n",
        "\n",
        "First, find a model on [the hub](https://huggingface.co/models). Anyone can upload their model for other people to use. (I'm using a sentiment analysis model from [this paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3489963)).\n",
        "\n",
        "Then, there are two objects that need to be initialized - a **tokenizer**, and a **model**\n",
        "\n",
        "* Tokenizer converts strings to lists of vocabulary ids that the model requires\n",
        "* Model takes the vocabulary ids and produces a prediction"
      ],
      "id": "qmXezUMg2idv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySLmJ0Z-oD35"
      },
      "source": [
        "![full_nlp_pipeline.png](attachment:full_nlp_pipeline.png)\n",
        "From [https://huggingface.co/course/chapter2/2?fw=pt](https://huggingface.co/course/chapter2/2?fw=pt)"
      ],
      "id": "ySLmJ0Z-oD35"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcsii_O42Z8Q"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"siebert/sentiment-roberta-large-english\")\n",
        "# Initialize the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"siebert/sentiment-roberta-large-english\")"
      ],
      "id": "Mcsii_O42Z8Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kT_zeWRBoD36"
      },
      "outputs": [],
      "source": [
        "inputs = \"I'm excited to learn about Hugging Face Transformers!\"\n",
        "tokenized_inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
        "outputs = model(**tokenized_inputs)\n",
        "\n",
        "labels = ['NEGATIVE', 'POSITIVE']\n",
        "prediction = torch.argmax(outputs.logits)\n",
        "\n",
        "\n",
        "print(\"Input:\")\n",
        "print(inputs)\n",
        "print()\n",
        "print(\"Tokenized Inputs:\")\n",
        "print_encoding(tokenized_inputs)\n",
        "print()\n",
        "print(\"Model Outputs:\")\n",
        "print(outputs)\n",
        "print()\n",
        "print(f\"The prediction is {labels[prediction]}\")"
      ],
      "id": "kT_zeWRBoD36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7jvH9haoD37"
      },
      "source": [
        "### 0.1 Tokenizers"
      ],
      "id": "a7jvH9haoD37"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43FLbwgz-X83"
      },
      "source": [
        "Pretrained models are implemented along with **tokenizers** that are used to preprocess their inputs. The tokenizers take raw strings or list of strings and output what are effectively dictionaries that contain the the model inputs.\n",
        "\n",
        "\n",
        "You can access tokenizers either with the Tokenizer class specific to the model you want to use (here DistilBERT), or with the AutoTokenizer class.\n",
        "Fast Tokenizers are written in Rust, while their slow versions are written in Python."
      ],
      "id": "43FLbwgz-X83"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu6L0lWG-X83",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertTokenizerFast, AutoTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")      # written in Python\n",
        "print(tokenizer)\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-cased\")  # written in Rust\n",
        "print(tokenizer)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\") # convenient! Defaults to Fast\n",
        "print(tokenizer)"
      ],
      "id": "Pu6L0lWG-X83"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrPzbBhR-X84"
      },
      "outputs": [],
      "source": [
        "# This is how you call the tokenizer\n",
        "input_str = \"Hugging Face Transformers is great!\"\n",
        "tokenized_inputs = tokenizer(input_str)\n",
        "\n",
        "\n",
        "print(\"Vanilla Tokenization\")\n",
        "print_encoding(tokenized_inputs)\n",
        "print()\n",
        "\n",
        "# Two ways to access:\n",
        "print(tokenized_inputs.input_ids)\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ],
      "id": "zrPzbBhR-X84"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_8C6L2G-X85"
      },
      "outputs": [],
      "source": [
        "cls = [tokenizer.cls_token_id]\n",
        "sep = [tokenizer.sep_token_id]\n",
        "\n",
        "# Tokenization happens in a few steps:\n",
        "input_tokens = tokenizer.tokenize(input_str)\n",
        "input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "input_ids_special_tokens = cls + input_ids + sep\n",
        "\n",
        "decoded_str = tokenizer.decode(input_ids_special_tokens)\n",
        "\n",
        "print(\"start:                \", input_str)\n",
        "print(\"tokenize:             \", input_tokens)\n",
        "print(\"convert_tokens_to_ids:\", input_ids)\n",
        "print(\"add special tokens:   \", input_ids_special_tokens)\n",
        "print(\"--------\")\n",
        "print(\"decode:               \", decoded_str)\n",
        "\n",
        "# NOTE that these steps don't create the attention mask or add the special characters"
      ],
      "id": "E_8C6L2G-X85"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdoZ3EEU-X86"
      },
      "outputs": [],
      "source": [
        "# For Fast Tokenizers, there's another option too:\n",
        "inputs = tokenizer._tokenizer.encode(input_str)\n",
        "\n",
        "print(input_str)\n",
        "print(\"-\"*5)\n",
        "print(f\"Number of tokens: {len(inputs)}\")\n",
        "print(f\"Ids: {inputs.ids}\")\n",
        "print(f\"Tokens: {inputs.tokens}\")\n",
        "print(f\"Special tokens mask: {inputs.special_tokens_mask}\")\n",
        "print()\n",
        "print(\"char_to_word gives the wordpiece of a character in the input\")\n",
        "char_idx = 8\n",
        "print(f\"For example, the {char_idx + 1}th character of the string is '{input_str[char_idx]}',\"+\\\n",
        "      f\" and it's part of wordpiece {inputs.char_to_token(char_idx)}, '{inputs.tokens[inputs.char_to_token(char_idx)]}'\")"
      ],
      "id": "tdoZ3EEU-X86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt5WV-6S-X87"
      },
      "outputs": [],
      "source": [
        "# Other cool tricks:\n",
        "# The tokenizer can return pytorch tensors\n",
        "model_inputs = tokenizer(\"Hugging Face Transformers is great!\", return_tensors=\"pt\")\n",
        "print(\"PyTorch Tensors:\")\n",
        "print_encoding(model_inputs)"
      ],
      "id": "vt5WV-6S-X87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI3bAzpeoD3_"
      },
      "outputs": [],
      "source": [
        "# You can pass multiple strings into the tokenizer and pad them as you need\n",
        "model_inputs = tokenizer([\"Hugging Face Transformers is great!\",\n",
        "                         \"The quick brown fox jumps over the lazy dog.\" +\\\n",
        "                         \"Then the dog got up and ran away because she didn't like foxes.\",\n",
        "                         ],\n",
        "                         return_tensors=\"pt\",\n",
        "                         padding=True,\n",
        "                         truncation=True)\n",
        "print(f\"Pad token: {tokenizer.pad_token} | Pad token id: {tokenizer.pad_token_id}\")\n",
        "print(\"Padding:\")\n",
        "print_encoding(model_inputs)"
      ],
      "id": "HI3bAzpeoD3_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "iSZat-nkoD3_"
      },
      "outputs": [],
      "source": [
        "# You can also decode a whole batch at once:\n",
        "print(\"Batch Decode:\")\n",
        "print(tokenizer.batch_decode(model_inputs.input_ids))\n",
        "print()\n",
        "print(\"Batch Decode: (no special characters)\")\n",
        "print(tokenizer.batch_decode(model_inputs.input_ids, skip_special_tokens=True))"
      ],
      "id": "iSZat-nkoD3_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmZNLz_noD4A"
      },
      "source": [
        "For more information about tokenizers, you can look at:\n",
        "[Hugging Face Transformers Docs](https://huggingface.co/docs/transformers/main_classes/tokenizer) and the [Hugging Face Tokenizers Library](https://huggingface.co/docs/tokenizers/python/latest/quicktour.html) (For the Fast Tokenizers). The Tokenizers Library even lets you train your own tokenizers!"
      ],
      "id": "JmZNLz_noD4A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6juLjnNt-X87"
      },
      "source": [
        "### 0.2 Models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Initializing models is very similar to initializing tokenizers. You can either use the model class specific to your model or you can use an AutoModel class. I tend to prefer AutoModel, especially when I want to compare models, because it's easy to specify the models as strings.\n",
        "\n",
        "While most of the pretrained transformers have similar architecture, if you there are additional weights, called \"heads\" that you have to train if you're doing sequence classification, question answering, or some other task. Hugging Face automatically sets up the architecture you need when you specify the model class. For example, we are doing sentiment analysis, so we are going to use `DistilBertForSequenceClassification`. If we were going to continue training DistilBERT on its masked-language modeling training objective, we would use `DistilBertForMaskedLM`, and if we just wanted the model's representations, maybe for our own downstream task, we could just use `DistilBertModel`.\n",
        "\n",
        "\n",
        "Here's a stylized picture of a model recreated from one found here: [https://huggingface.co/course/chapter2/2?fw=pt](https://huggingface.co/course/chapter2/2?fw=pt).\n",
        "![model_illustration.png](attachment:model_illustration.png)\n",
        "\n",
        "\n",
        "Here are some examples.\n",
        "```\n",
        "*\n",
        "*ForMaskedLM\n",
        "*ForSequenceClassification\n",
        "*ForTokenClassification\n",
        "*ForQuestionAnswering\n",
        "*ForMultipleChoice\n",
        "...\n",
        "```\n",
        "where `*` can be `AutoModel` or a specific pretrained model (e.g. `DistilBert`)\n",
        "\n",
        "\n",
        "There are three types of models:\n",
        "* Encoders (e.g. BERT)\n",
        "* Decoders (e.g. GPT2)\n",
        "* Encoder-Decoder models (e.g. BART or T5)\n",
        "\n",
        "The task-specific classes you have available depend on what type of model you're dealing with.\n",
        "\n",
        "\n",
        "A full list of choices are available in the [docs](https://huggingface.co/docs/transformers/model_doc/auto). Note that not all models are compatible with all model architectures, for example DistilBERT is not compatible with the Seq2Seq models because it only consists of an encoder.\n"
      ],
      "id": "6juLjnNt-X87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXm1K2sF-X88",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, DistilBertForSequenceClassification\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=2)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=2)\n"
      ],
      "id": "RXm1K2sF-X88"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1opFV7Vi-X88"
      },
      "source": [
        "We get a warning here because the sequence classification parameters haven't been trained yet.\n",
        "\n",
        "Passing inputs to the model is super easy. They take inputs as keyword arguments"
      ],
      "id": "1opFV7Vi-X88"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDZ72k-U-X89"
      },
      "outputs": [],
      "source": [
        "model_inputs = tokenizer(input_str, return_tensors=\"pt\")\n",
        "\n",
        "# Option 1\n",
        "model_outputs = model(input_ids=model_inputs.input_ids, attention_mask=model_inputs.attention_mask)\n",
        "\n",
        "# Option 2 - the keys of the dictionary the tokenizer returns are the same as the keyword arguments\n",
        "#            the model expects\n",
        "\n",
        "# f({k1: v1, k2: v2}) = f(k1=v1, k2=v2)\n",
        "\n",
        "model_outputs = model(**model_inputs)\n",
        "\n",
        "print(model_inputs)\n",
        "print()\n",
        "print(model_outputs)\n",
        "print()\n",
        "print(f\"Distribution over labels: {torch.softmax(model_outputs.logits, dim=1)}\")"
      ],
      "id": "TDZ72k-U-X89"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRRqhVUloD4C"
      },
      "source": [
        "If you notice, it's a bit weird that we have two classes for a binary classification task - you could easily have a single class and just choose a threshold. It's like this because of how huggingface models calculate the loss. This will increase the number of parameters we have, but shouldn't otherwise affect performance."
      ],
      "id": "oRRqhVUloD4C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvie4gYD-X8-"
      },
      "source": [
        "These models are just Pytorch Modules! You can can calculate the loss with your `loss_func` and call `loss.backward`. You can use any of the optimizers or learning rate schedulers that you used"
      ],
      "id": "rvie4gYD-X8-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irxo7sDboD4C"
      },
      "outputs": [],
      "source": [
        "# You can calculate the loss like normal\n",
        "label = torch.tensor([1])\n",
        "loss = torch.nn.functional.cross_entropy(model_outputs.logits, label)\n",
        "print(loss)\n",
        "loss.backward()\n",
        "\n",
        "# You can get the parameters\n",
        "list(model.named_parameters())[0]"
      ],
      "id": "Irxo7sDboD4C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpHeG1zDoD4D"
      },
      "source": [
        "Hugging Face provides an additional easy way to calculate the loss as well:"
      ],
      "id": "mpHeG1zDoD4D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S148gCyG-X8-"
      },
      "outputs": [],
      "source": [
        "# To calculate the loss, we need to pass in a label:\n",
        "model_inputs = tokenizer(input_str, return_tensors=\"pt\")\n",
        "\n",
        "labels = ['NEGATIVE', 'POSITIVE']\n",
        "model_inputs['labels'] = torch.tensor([1])\n",
        "\n",
        "model_outputs = model(**model_inputs)\n",
        "\n",
        "\n",
        "print(model_outputs)\n",
        "print()\n",
        "print(f\"Model predictions: {labels[model_outputs.logits.argmax()]}\")"
      ],
      "id": "S148gCyG-X8-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y6E3IxzoD4E"
      },
      "source": [
        "One final note - you can get the hidden states and attention weights from the models really easily. This is particularly helpful if you're working on an analysis project. (For example, see [What does BERT look at?](https://arxiv.org/abs/1906.04341))."
      ],
      "id": "7Y6E3IxzoD4E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WzqhpquoD4E"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"distilbert-base-cased\", output_attentions=True, output_hidden_states=True)\n",
        "model.eval()\n",
        "\n",
        "model_inputs = tokenizer(input_str, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    model_output = model(**model_inputs)\n",
        "\n",
        "\n",
        "print(\"Hidden state size (per layer):  \", model_output.hidden_states[0].shape)\n",
        "print(\"Attention head size (per layer):\", model_output.attentions[0].shape)     # (layer, batch, query_word_idx, key_word_idxs)\n",
        "                                                                               # y-axis is query, x-axis is key\n",
        "print(model_output)"
      ],
      "id": "5WzqhpquoD4E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH_MAK-soD4F"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(model_inputs.input_ids[0])\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "n_layers = len(model_output.attentions)\n",
        "n_heads = len(model_output.attentions[0][0])\n",
        "fig, axes = plt.subplots(6, 12)\n",
        "fig.set_size_inches(18.5*2, 10.5*2)\n",
        "for layer in range(n_layers):\n",
        "    for i in range(n_heads):\n",
        "        axes[layer, i].imshow(model_output.attentions[layer][0, i])\n",
        "        axes[layer][i].set_xticks(list(range(10)))\n",
        "        axes[layer][i].set_xticklabels(labels=tokens, rotation=\"vertical\")\n",
        "        axes[layer][i].set_yticks(list(range(10)))\n",
        "        axes[layer][i].set_yticklabels(labels=tokens)\n",
        "\n",
        "        if layer == 5:\n",
        "            axes[layer, i].set(xlabel=f\"head={i}\")\n",
        "        if i == 0:\n",
        "            axes[layer, i].set(ylabel=f\"layer={layer}\")\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3)\n",
        "plt.show()"
      ],
      "id": "SH_MAK-soD4F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uumcErs2-X80"
      },
      "source": [
        "## Part 1: Finetuning\n",
        "\n",
        "For your projects, you are much more likely to want to finetune a pretrained model. This is a little bit more involved, but is still quite easy."
      ],
      "id": "uumcErs2-X80"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDdGp4Ua-X81"
      },
      "source": [
        "### 2.1 Loading in a dataset\n",
        "\n",
        "In addition to having models, the [the hub](https://huggingface.co/datasets) also has datasets."
      ],
      "id": "WDdGp4Ua-X81"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTsW-Wwi-X81"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "\n",
        "\n",
        "DataLoader(zip(list1, list2))\n",
        "\n",
        "\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "\n",
        "\n",
        "# Just take the first 50 tokens for speed/running on cpu\n",
        "def truncate(example):\n",
        "    return {\n",
        "        'text': \" \".join(example['text'].split()[:50]),\n",
        "        'label': example['label']\n",
        "    }\n",
        "\n",
        "# Take 128 random examples for train and 32 validation\n",
        "small_imdb_dataset = DatasetDict(\n",
        "    train=imdb_dataset['train'].shuffle(seed=1111).select(range(128)).map(truncate),\n",
        "    val=imdb_dataset['train'].shuffle(seed=1111).select(range(128, 160)).map(truncate),\n",
        ")"
      ],
      "id": "OTsW-Wwi-X81"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCaX-gNo0OEV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "small_imdb_dataset"
      ],
      "id": "vCaX-gNo0OEV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBS4c44A-X82"
      },
      "outputs": [],
      "source": [
        "small_imdb_dataset['train'][:10]"
      ],
      "id": "bBS4c44A-X82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bjqop3N-X8_"
      },
      "outputs": [],
      "source": [
        "# Prepare the dataset - this tokenizes the dataset in batches of 16 examples.\n",
        "small_tokenized_dataset = small_imdb_dataset.map(\n",
        "    lambda example: tokenizer(example['text'], padding=True, truncation=True),\n",
        "    batched=True,\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "small_tokenized_dataset = small_tokenized_dataset.remove_columns([\"text\"])\n",
        "small_tokenized_dataset = small_tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "small_tokenized_dataset.set_format(\"torch\")"
      ],
      "id": "3bjqop3N-X8_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "450eUYlf-X8_"
      },
      "outputs": [],
      "source": [
        "small_tokenized_dataset['train'][0:2]"
      ],
      "id": "450eUYlf-X8_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3e7_htt-X8_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(small_tokenized_dataset['train'], batch_size=16)\n",
        "eval_dataloader = DataLoader(small_tokenized_dataset['val'], batch_size=16)"
      ],
      "id": "Q3e7_htt-X8_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRm6Tw_z-X8-"
      },
      "source": [
        "### 2.2 Training\n",
        "\n",
        "To train your models, you can just use the same kind of training loop that you would use in Pytorch. Hugging Face models are also `torch.nn.Module`s so backpropagation happens the same way and you can even use the same optimizers. Hugging Face also includes optimizers and learning rate schedules that were used to train Transformer models, so you can use these too.\n",
        "\n",
        "For optimization, we're using the AdamW Optimizer, which is almost identical to Adam except it also includes weight decay.\n",
        "And we're using a linear learning rate scheduler, which reduces the learning rate a little bit after each training step over the course of training.\n",
        "\n",
        "There are other optimizers and learning rate schedulers you can use, but these are the default. If you want to explore, you can look at the ones [Hugging Face offers](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#schedules), the ones available through [Pytorch](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) (e.g. [ReduceLROnPlateau](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html), which only decreases the learning rate when the validation loss stops decreasing), or write your own (like the one in Assignment 4)."
      ],
      "id": "qRm6Tw_z-X8-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7CvjTIv-X9A"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=2)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = 3 * len(train_dataloader)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "for epoch in range(num_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    for batch_i, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # batch = ([text1, text2], [0, 1])\n",
        "\n",
        "        output = model(**batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output.loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    for batch_i, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            output = model(**batch)\n",
        "        loss += output.loss\n",
        "\n",
        "    avg_val_loss = loss / len(eval_dataloader)\n",
        "    print(f\"Validation loss: {avg_val_loss}\")\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        print(\"Saving checkpoint!\")\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': best_val_loss,\n",
        "            },\n",
        "            f\"checkpoints/epoch_{epoch}.pt\"\n",
        "        )"
      ],
      "id": "A7CvjTIv-X9A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrfE9c04-X9A"
      },
      "source": [
        "While you can use PyTorch to train your models like we did in Assignment 4, Hugging Face offers a powerful `Trainer` class to handle most needs. I think it works pretty well, though there are some customizations I'd recommend."
      ],
      "id": "YrfE9c04-X9A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1fb3a8197d414867834988efc2a29a9a",
            "d0c5112c973d4bb7831e7efef64bfb24",
            "0283e6553aac4bdb82e0946e75f70fdc",
            "48071e40359e4f75b7c5cf0ee8947b23"
          ]
        },
        "id": "fQDkqtT7-X9B",
        "outputId": "77c36c60-d22f-42e6-bb81-de7a25141b27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset imdb (/Users/benjaminnewman/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0283e6553aac4bdb82e0946e75f70fdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at /Users/benjaminnewman/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-3f14c120716ea8f9.arrow\n",
            "Loading cached processed dataset at /Users/benjaminnewman/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b094db9269652aeb.arrow\n",
            "Loading cached shuffled indices for dataset at /Users/benjaminnewman/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-3f14c120716ea8f9.arrow\n",
            "Loading cached processed dataset at /Users/benjaminnewman/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-74eca81b49fca454.arrow\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48071e40359e4f75b7c5cf0ee8947b23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /Users/benjaminnewman/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-0dcd32840343eeca.arrow\n"
          ]
        }
      ],
      "source": [
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "\n",
        "small_imdb_dataset = DatasetDict(\n",
        "    train=imdb_dataset['train'].shuffle(seed=1111).select(range(128)).map(truncate),\n",
        "    val=imdb_dataset['train'].shuffle(seed=1111).select(range(128, 160)).map(truncate),\n",
        ")\n",
        "\n",
        "small_tokenized_dataset = small_imdb_dataset.map(\n",
        "    lambda example: tokenizer(example['text'], truncation=True),\n",
        "    batched=True,\n",
        "    batch_size=16\n",
        ")"
      ],
      "id": "fQDkqtT7-X9B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RULukU5eoD4M"
      },
      "source": [
        "`TrainingArguments` specifies different training parameters like how often to evaluate and save model checkpoints, where to save them, etc. There are **many** aspects you can customize and it's worth checking them out [here](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments). Some things you can control include:\n",
        "* learning rate, weight decay, gradient clipping,\n",
        "* checkpointing, logging, and evaluation frequency\n",
        "* where you log to (default is tensorboard, but if you use WandB or MLFlow they have integrations)\n",
        "\n",
        "The `Trainer` actually performs the training. You can pass it the `TrainingArguments`, model, the datasets, tokenizer, optimizer, and even model checkpoints to resume training from. The `compute_metrics` function is called at the end of evaluation/validation to calculate evaluation metrics."
      ],
      "id": "RULukU5eoD4M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1cfd55a3d670455e8056830042156384"
          ]
        },
        "id": "FEmERCu_-X9B",
        "outputId": "0698d0b4-f168-4e99-acc9-45826056c271",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/benjaminnewman/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels=2)\n",
        "\n",
        "arguments = TrainingArguments(\n",
        "    output_dir=\"sample_hf_trainer\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\", # run validation at the end of each epoch\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    load_best_model_at_end=True,\n",
        "    seed=224\n",
        ")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # calculates the accuracy\n",
        "    return {\"accuracy\": np.mean(predictions == labels)}\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=arguments,\n",
        "    train_dataset=small_tokenized_dataset['train'],\n",
        "    eval_dataset=small_tokenized_dataset['val'], # change to test when you do your final evaluation!\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "id": "FEmERCu_-X9B"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbyK1W95-X9B"
      },
      "source": [
        "#### Callbacks: Logging and Early Stopping\n",
        "\n",
        "\n",
        "Hugging Face Transformers also allows you to write `Callbacks` if you want certain things to happen at different points during training (e.g. after evaluation or after an epoch has finished). For example, there is a callback for early stopping, and I usually write one for logging as well.\n",
        "\n",
        "For more information on callbacks see [here](https://huggingface.co/docs/transformers/main_classes/callback#transformers.TrainerCallback)."
      ],
      "id": "MbyK1W95-X9B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKO3TkAnoD4N"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback, EarlyStoppingCallback\n",
        "\n",
        "class LoggingCallback(TrainerCallback):\n",
        "    def __init__(self, log_path):\n",
        "        self.log_path = log_path\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        _ = logs.pop(\"total_flos\", None)\n",
        "        if state.is_local_process_zero:\n",
        "            with open(self.log_path, \"a\") as f:\n",
        "                f.write(json.dumps(logs) + \"\\n\")\n",
        "\n",
        "\n",
        "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=0.0))\n",
        "trainer.add_callback(LoggingCallback(\"sample_hf_trainer/log.jsonl\"))"
      ],
      "id": "vKO3TkAnoD4N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tunwonc2-X9C",
        "outputId": "afceb412-cd45-48ee-a45c-e2767ec8357d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running training *****\n",
            "  Num examples = 128\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 24\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 02:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.681011</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.781250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.679451</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 32\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to sample_hf_trainer/checkpoint-8\n",
            "Configuration saved in sample_hf_trainer/checkpoint-8/config.json\n",
            "Model weights saved in sample_hf_trainer/checkpoint-8/pytorch_model.bin\n",
            "tokenizer config file saved in sample_hf_trainer/checkpoint-8/tokenizer_config.json\n",
            "Special tokens file saved in sample_hf_trainer/checkpoint-8/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 32\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to sample_hf_trainer/checkpoint-16\n",
            "Configuration saved in sample_hf_trainer/checkpoint-16/config.json\n",
            "Model weights saved in sample_hf_trainer/checkpoint-16/pytorch_model.bin\n",
            "tokenizer config file saved in sample_hf_trainer/checkpoint-16/tokenizer_config.json\n",
            "Special tokens file saved in sample_hf_trainer/checkpoint-16/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 32\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to sample_hf_trainer/checkpoint-24\n",
            "Configuration saved in sample_hf_trainer/checkpoint-24/config.json\n",
            "Model weights saved in sample_hf_trainer/checkpoint-24/pytorch_model.bin\n",
            "tokenizer config file saved in sample_hf_trainer/checkpoint-24/tokenizer_config.json\n",
            "Special tokens file saved in sample_hf_trainer/checkpoint-24/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from sample_hf_trainer/checkpoint-24 (score: 0.6794506311416626).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=24, training_loss=0.6890308062235514, metrics={'train_runtime': 135.037, 'train_samples_per_second': 2.844, 'train_steps_per_second': 0.178, 'train_loss': 0.6890308062235514, 'epoch': 3.0})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train the model\n",
        "trainer.train()"
      ],
      "id": "tunwonc2-X9C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q185j9V-X9C",
        "outputId": "2060b795-3bde-4df6-a6d3-68b909e369c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 32\n",
            "  Batch size = 16\n"
          ]
        }
      ],
      "source": [
        "# evaluating the model is very easy\n",
        "\n",
        "# results = trainer.evaluate()                           # just gets evaluation metrics\n",
        "results = trainer.predict(small_tokenized_dataset['val']) # also gives you predictions"
      ],
      "id": "_Q185j9V-X9C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ0aGxeh-X9D",
        "outputId": "3f5b3e58-e4b0-4d11-f5d3-9e2b1c51fd0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 0.05993838,  0.05080247],\n",
              "       [ 0.06414214,  0.05759765],\n",
              "       [ 0.0469191 ,  0.03830711],\n",
              "       [ 0.07076851,  0.03744037],\n",
              "       [ 0.06158166,  0.06742534],\n",
              "       [ 0.04300443,  0.07595264],\n",
              "       [ 0.05682347,  0.01483105],\n",
              "       [ 0.07363723,  0.03842184],\n",
              "       [ 0.01397173,  0.09803831],\n",
              "       [ 0.00271686,  0.0901159 ],\n",
              "       [ 0.04887585,  0.07860844],\n",
              "       [ 0.09564517,  0.01762218],\n",
              "       [ 0.06839062,  0.04889553],\n",
              "       [ 0.04660409,  0.0411428 ],\n",
              "       [ 0.06957815,  0.02991551],\n",
              "       [ 0.07735568,  0.02075466],\n",
              "       [ 0.04797686,  0.04933587],\n",
              "       [ 0.03351745,  0.08934984],\n",
              "       [ 0.04969639,  0.04358277],\n",
              "       [-0.01777451,  0.1044005 ],\n",
              "       [ 0.1038493 ,  0.00314836],\n",
              "       [ 0.05385269,  0.05502943],\n",
              "       [ 0.0813157 ,  0.06455064],\n",
              "       [ 0.03866698,  0.05409538],\n",
              "       [ 0.00791029,  0.0710441 ],\n",
              "       [ 0.02850733,  0.07708664],\n",
              "       [ 0.06480809,  0.0636038 ],\n",
              "       [ 0.02842036,  0.09321532],\n",
              "       [ 0.06331588,  0.0501368 ],\n",
              "       [ 0.06383031,  0.00592049],\n",
              "       [ 0.05257577,  0.02481269],\n",
              "       [ 0.05283061,  0.09818912]], dtype=float32), label_ids=array([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 0, 1]), metrics={'test_loss': 0.6794506311416626, 'test_accuracy': 0.6875, 'test_runtime': 2.9595, 'test_samples_per_second': 10.812, 'test_steps_per_second': 0.676})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ],
      "id": "UJ0aGxeh-X9D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSGsZo3xoD4O",
        "outputId": "e5970f7b-af03-44d0-f171-e2bee88b438e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file sample_hf_trainer/checkpoint-24/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"sample_hf_trainer/checkpoint-24\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file sample_hf_trainer/checkpoint-24/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at sample_hf_trainer/checkpoint-24.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POSITIVE\n"
          ]
        }
      ],
      "source": [
        "# To load our saved model, we can pass the path to the checkpoint into the `from_pretrained` method:\n",
        "test_str = \"I enjoyed the movie!\"\n",
        "\n",
        "finetuned_model = AutoModelForSequenceClassification.from_pretrained(\"sample_hf_trainer/checkpoint-24\")\n",
        "model_inputs = tokenizer(test_str, return_tensors=\"pt\")\n",
        "prediction = torch.argmax(finetuned_model(**model_inputs).logits)\n",
        "print([\"NEGATIVE\", \"POSITIVE\"][prediction])"
      ],
      "id": "kSGsZo3xoD4O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MllSTgehoD4O"
      },
      "source": [
        "Included here are also some practical tips for fine-tuning:\n",
        "\n",
        "**Good default hyperparameters.** The hyperparameters you will depend on your task and dataset. You should do a hyperparameter search to find the best ones. That said, here are some good initial values for fine-tuning.\n",
        "* Epochs: {2, 3, 4} (larger amounts of data need fewer epochs)\n",
        "* Batch size (bigger is better: as large as you can make it)\n",
        "* Optimizer: AdamW\n",
        "* AdamW learning rate: {2e-5, 5e-5}\n",
        "* Learning rate scheduler: linear warm up for first {0, 100, 500} steps of training\n",
        "* weight_decay (l2 regularization): {0, 0.01, 0.1}\n",
        "\n",
        "You should monitor your validation loss to decide when you've found good hyperparameters."
      ],
      "id": "MllSTgehoD4O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsWGQfrm-X9D"
      },
      "source": [
        "There's a lot more that we can integrate into the Trainer to make it more useful including logging, saving model checkpoints, and more! You can even sub-class it to add your own personalized components. You can check out [this link](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer) for more information about the Trainer."
      ],
      "id": "gsWGQfrm-X9D"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nCrUosgoD4P"
      },
      "source": [
        "## Appendix 0: Generation\n",
        "\n",
        "In the example above we finetuned the model on a classification task, but you can also finetune models on generation tasks. The `generate` function makes it easy to generate from these models. For example."
      ],
      "id": "9nCrUosgoD4P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfQEV8EKoD4P",
        "outputId": "3ac4a200-9a84-4866-fb17-644736efda17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /Users/benjaminnewman/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"distilgpt2\",\n",
            "  \"_num_labels\": 1,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 6,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /Users/benjaminnewman/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "gpt2_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "gpt2 = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
        "gpt2.config.pad_token_id = gpt2.config.eos_token_id  # Prevents warning during decoding"
      ],
      "id": "QfQEV8EKoD4P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5wo61xmoD4Q",
        "outputId": "cada15b1-bf81-41e0-f384-5860a3bd1999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-87dbedc4e41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Once upon a time\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenized_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gpt2_tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "prompt = \"Once upon a time\"\n",
        "\n",
        "tokenized_prompt = gpt2_tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "for i in range(10):\n",
        "    output = gpt2.generate(**tokenized_prompt,\n",
        "                  max_length=50,\n",
        "                  do_sample=True,\n",
        "                  top_p=0.9)\n",
        "\n",
        "    print(f\"{i + 1}) {gpt2_tokenizer.batch_decode(output)[0]}\")"
      ],
      "id": "G5wo61xmoD4Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLAHLU4q9HYQ"
      },
      "source": [
        "## Appendix 1: Defining Custom Datasets\n",
        "\n",
        "There are a few ways to go about defining datasets, but I'm going to show an example using Pytorch Dataloaders. This example uses an encoder-decoder dataaset,the [E2E Dataset](https://arxiv.org/abs/1706.09254), which is maps structured information about restaurants to natural language descriptions."
      ],
      "id": "QLAHLU4q9HYQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLqz11UioD4Q"
      },
      "outputs": [],
      "source": [
        "# Option 1: Load into Hugging Face Datasets\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "df = pd.read_csv(\"e2e-dataset/trainset.csv\")\n",
        "custom_dataset = Dataset.from_pandas(df)"
      ],
      "id": "MLqz11UioD4Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRauc5JBoD4R"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class E2EDataset(Dataset):\n",
        "    \"\"\"Tokenize data when we call __getitem__\"\"\"\n",
        "    def __init__(self, path, tokenizer):\n",
        "        with open(path, newline=\"\") as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader) # skip the heading\n",
        "            self.data = [{\"source\": row[0], \"target\": row[1]} for row in reader]\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        inputs = self.tokenizer(self.data[i]['source'])\n",
        "        labels = self.tokenizer(self.data[i]['target'])\n",
        "        inputs['labels'] = labels.input_ids\n",
        "        return inputs\n"
      ],
      "id": "lRauc5JBoD4R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eRu5mFIpoD4R",
        "outputId": "ae18b079-d451-4218-ff4e-44625821c7c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.da0f3c0e2dc1c2fecc46738a1ebf4806f2fc36aae3d5c1947f21e063e7cab34b\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"facebook/bart-base\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/facebook/bart-base/resolve/main/vocab.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/43978bdeaa326572886b44fcfed82f932f76571095ce31973e51c3da8ccade7f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/facebook/bart-base/resolve/main/merges.txt from cache at /Users/benjaminnewman/.cache/huggingface/transformers/3c167ed8af56e6605eeb794b63a79d65d85e6708c9b04408d41946337030f5cd.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/a878fcd69bba037c9b1b227f4213579ae43d0aaa9374e167bc6c5f41b1cfeb30.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/facebook/bart-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/facebook/bart-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /Users/benjaminnewman/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.da0f3c0e2dc1c2fecc46738a1ebf4806f2fc36aae3d5c1947f21e063e7cab34b\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"facebook/bart-base\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bart_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')"
      ],
      "id": "eRu5mFIpoD4R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I32zL1nEoD4S",
        "outputId": "a22bfe6b-2402-445a-fff7-2027dfb898d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['name[The Vaults], eatType[pub], priceRange[more than 30], customer rating[5 out of 5], near[Caf Adriatic]', 'name[The Cambridge Blue], eatType[pub], food[English], priceRange[cheap], near[Caf Brazil]', 'name[The Eagle], eatType[coffee shop], food[Japanese], priceRange[less than 20], customer rating[low], area[riverside], familyFriendly[yes], near[Burger King]', 'name[The Mill], eatType[coffee shop], food[French], priceRange[20-25], area[riverside], near[The Sorrento]', 'name[Loch Fyne], food[French], customer rating[high], area[riverside], near[The Rice Boat]', 'name[Bibimbap House], food[English], priceRange[moderate], area[riverside], near[Clare Hall]', 'name[The Rice Boat], food[French], customer rating[average], area[riverside], familyFriendly[no]', 'name[The Wrestlers], eatType[coffee shop], food[Japanese], priceRange[less than 20], area[riverside], familyFriendly[no], near[Raja Indian Cuisine]', 'name[Aromi], eatType[coffee shop], food[French], customer rating[low], area[city centre], familyFriendly[no]', 'name[The Phoenix], food[Fast food], priceRange[moderate], customer rating[3 out of 5], area[riverside]']\n"
          ]
        }
      ],
      "source": [
        "dataset = E2EDataset(\"e2e-dataset/trainset.csv\", bart_tokenizer)"
      ],
      "id": "I32zL1nEoD4S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I50Sh862oD4T",
        "outputId": "781fb25c-120a-45e4-fa69-696827803c32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[   0,  713,   16,    5,   78, 1296,    4,    2],\n",
              "        [   0,  713,   16,    5,  200, 1296,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[    0, 41858,   112,     2],\n",
              "        [    0, 41858,   132,     2]])}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bart_tokenizer.prepare_seq2seq_batch(src_texts=[\"This is the first test.\", \"This is the second test.\"], tgt_texts=[\"Target 1\", \"Target 2\"], return_tensors=\"pt\")"
      ],
      "id": "I50Sh862oD4T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8frTRD3oD4T",
        "outputId": "a08e33db-9f55-47ef-be08-71cc57586625"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [3672, 58, 464, 21314, 4357, 4483, 6030, 58, 12984, 4357, 2756, 17257, 58, 3549, 621, 4248, 1270, 4357, 6491, 7955, 58, 20, 503, 286, 642, 4357, 1474, 58, 34, 1878, 2634, 1215, 380, 1512, 60], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [464, 21314, 2240, 1474, 42151, 1215, 380, 1512, 468, 257, 642, 3491, 7955, 13, 220, 29431, 923, 379, 4248, 1270, 13]}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ],
      "id": "w8frTRD3oD4T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHI3KuNZ-X8w"
      },
      "source": [
        "## Appendix 2: Pipelines\n",
        "\n",
        "There are some standard NLP tasks like sentiment classification or question answering where there are already pre-trained (and fine-tuned!) models available through Hugging Face Transformer's [_Pipeline_](https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/pipelines#transformers.pipeline) interface.\n",
        "\n",
        "For your projects, you likely won't be using it too much, but it's still worth knowing about!\n",
        "\n",
        "Here's an example with Sentiment Analysis:"
      ],
      "id": "tHI3KuNZ-X8w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "c05f9ffaa0cd45d789ec4dc3f033f820",
            "948ae10118da4bb6968202f14024c804",
            "2c7ffe282e5b45afa1817b94211e6e69",
            "5a189c79d1c84e6290136eadb5869d50",
            "5030fd2ba5ac45b8970fa69307214296",
            "00957de9cc184709a01368bc497e09ad",
            "c90cb767246145a880f50970d92a490d",
            "a732e83c51d54bb198c8ea6198a160ae",
            "5b611c19012f41ad860a1277d7ebed2d",
            "36816ad17f834690a2182f46ef077166",
            "1cb8a256c12c46cbbf6e85fcc84cd771",
            "ba5efd9a16284ca69cf9109e829ce4e1",
            "41c8df7396d7416887474be68c8677ce",
            "1c0397656ed84f6c8ae6fe993b0d4ab1",
            "b3a15d03a55c46b7851b2c9411be1e9e",
            "fa3ab5e902c549d68f6ea80525176274",
            "3ea541f4456142d2a185c63c995dd952",
            "a6c5b54662ee41bdac56de1566754506",
            "f96755f75c3e403b957f39e1bdba328e",
            "1d28eb657bfd464bb724a9154b5364ff",
            "ad51b35e49404d4ba75e28a65e4149ec",
            "9489b9785f5d4413b67c26814d6c431c",
            "37b1389dc4ad4c09820a5a82a5e4cfa0",
            "c41e9e9a625542a3826672040c8f67b2",
            "f54c8e32ae1a40a1b5ef335cdee602de",
            "33501c1674444c2c82be30af6b0e7d6c",
            "fc926dfcc0b54518a3848d889bdb0115",
            "8fd3e923bf7c43479ce9577cfccb2c5b",
            "604ca22657b8441fa639d01ea6a1280d",
            "e85af90b09fa4ef1960873d231224c73",
            "a84ffbc1c8974a5eb87fe481d4fe3a55",
            "3867c2734aec4a2487c2ceb2550080b6",
            "d3df10a819e54a0dba06b710ccda97f2",
            "61ed9d5eb6844598b787f992b7b1d869",
            "4db418532e6f4559b77ee1e93441c435",
            "f21d3a9b305e4443ac1f4048fc1e0542",
            "367fe5ad116447d0bbd52690cc967379",
            "0bd92956201547ba81b2bd57353c3fbe",
            "dc17aad891ab4e209e0b843cceb15fea",
            "a16c5be76a9148c086911e4fe144e25f",
            "df857a1953f14153af1e048c129debe4",
            "56c0f1582e9244ca92731edca6f15182",
            "b7c811d669aa46949839eb002bbc0527",
            "de4b4e88897841299a989c767c481684",
            "21fa5996e3924a9596c3e4cd5c67222e",
            "1a8ffac0cf4340a5b9ca1d97b06284bb",
            "7bcbdf196c8f427ca3f52b721856b216",
            "ad1a44ecca6f456485fe7a0564fbba06",
            "b64dc1362b66403283c35ed1486d03ba",
            "b7138a19e4ee4387a51b91a12adc6deb",
            "89696c9cf2ce40b59430a1c73416bbe9",
            "4b0bf9c30f354cf98762e45fe2f60eca",
            "2cbbc3b940e042edb1c40804e68c8c4a",
            "d4f9e2eb5b1f4ab5a6f97175c0d72289",
            "1eedcf774c5745dbaf7bc2ca3fb79ed6",
            "99ca3303ff634644902c265c7979bdc1",
            "02cbed4eaedb40ad972511cfcbbc0248",
            "9a3c5376f980483786b51ef772ff55b2",
            "3283d6e30fd84386b242f93291c8cf19",
            "7528012daa0144119b1b5503bc67d1d2",
            "b65490f5a5434f5196f58dcfb74dfbe7",
            "83353edb1cd1455b80505f0e930bdaef",
            "b639053b79f14779a36791a8beae9f43",
            "9552a571893a4a398a0751f6a6ecd023",
            "931f60229a234b7084cdff8ee64a172c",
            "9e9db1285fc8471ca4c8ce7726238fb1"
          ]
        },
        "collapsed": true,
        "id": "gOj5ODS0-X8x",
        "outputId": "004b2810-b01e-4702-df85-b5b052917b00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c05f9ffaa0cd45d789ec4dc3f033f820",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/687 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba5efd9a16284ca69cf9109e829ce4e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37b1389dc4ad4c09820a5a82a5e4cfa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61ed9d5eb6844598b787f992b7b1d869",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21fa5996e3924a9596c3e4cd5c67222e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99ca3303ff634644902c265c7979bdc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")"
      ],
      "id": "gOj5ODS0-X8x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5wZuMG2-X8y"
      },
      "source": [
        "You can run the pipeline by just calling it on a string"
      ],
      "id": "D5wZuMG2-X8y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrygLkiQ-X8y",
        "outputId": "278b0ede-8466-4072-e341-b832a346a7a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.998448371887207}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis(\"Hugging Face Transformers is really cool!\")"
      ],
      "id": "GrygLkiQ-X8y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e2E8qKH-X8z"
      },
      "source": [
        "Or on a list of strings:"
      ],
      "id": "0e2E8qKH-X8z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpBvCpVM-X8z",
        "outputId": "5386442c-7aca-41d5-91aa-40788fe25564"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9988769888877869},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994940757751465}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_analysis([\"I didn't know if I would like Hkarl, but it turned out pretty good.\",\n",
        "                    \"I didn't know if I would like Hkarl, and it was just as bad as I'd heard.\"])"
      ],
      "id": "EpBvCpVM-X8z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptc0BViy-X80"
      },
      "source": [
        "You can find more information on pipelines (including which ones are available) [here](https://huggingface.co/docs/transformers/main_classes/pipelines)"
      ],
      "id": "Ptc0BViy-X80"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oRAmG_w-X9H"
      },
      "source": [
        "## Appendix 4: Masked Language Modeling"
      ],
      "id": "3oRAmG_w-X9H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZXD2-Gsu-X9H",
        "outputId": "0ffba40b-f5da-45f7-dfaf-519ac1e80ffa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", fast=True)\n",
        "bert = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\")"
      ],
      "id": "ZXD2-Gsu-X9H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvfHGKrq-X9I",
        "outputId": "619a8a26-359b-4919-f789-1d09a267caf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'sequence': '[CLS] I am excited to learn about HuggingFace! [SEP]',\n",
              "  'score': 0.3552912473678589,\n",
              "  'token': 7215,\n",
              "  'token_str': 'excited'},\n",
              " {'sequence': '[CLS] I am going to learn about HuggingFace! [SEP]',\n",
              "  'score': 0.15621154010295868,\n",
              "  'token': 1280,\n",
              "  'token_str': 'going'},\n",
              " {'sequence': '[CLS] I am eager to learn about HuggingFace! [SEP]',\n",
              "  'score': 0.07893437147140503,\n",
              "  'token': 9582,\n",
              "  'token_str': 'eager'},\n",
              " {'sequence': '[CLS] I am here to learn about HuggingFace! [SEP]',\n",
              "  'score': 0.03559965267777443,\n",
              "  'token': 1303,\n",
              "  'token_str': 'here'},\n",
              " {'sequence': '[CLS] I am delighted to learn about HuggingFace! [SEP]',\n",
              "  'score': 0.03524085506796837,\n",
              "  'token': 17261,\n",
              "  'token_str': 'delighted'}]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"I am [MASK] to learn about HuggingFace!\"\n",
        "model = pipeline(\"fill-mask\", \"bert-base-cased\")\n",
        "model(prompt)"
      ],
      "id": "fvfHGKrq-X9I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B2qek-v-X9I",
        "outputId": "7eba678e-e6c4-469d-8f6f-1e0c9329d927",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am [MASK] to learn about HuggingFace!\n",
            "  1) excited\t0.355\n",
            "  2) going\t0.156\n",
            "  3) eager\t0.079\n",
            "  4) here\t0.036\n",
            "  5) delighted\t0.035\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "mask_index = np.where(inputs['input_ids'] == tokenizer.mask_token_id)\n",
        "outputs = bert(**inputs)\n",
        "top_5_predictions = torch.softmax(outputs.logits[mask_index], dim=1).topk(5)\n",
        "\n",
        "print(prompt)\n",
        "for i in range(5):\n",
        "    prediction = tokenizer.decode(top_5_predictions.indices[0, i])\n",
        "    prob = top_5_predictions.values[0, i]\n",
        "    print(f\"  {i+1}) {prediction}\\t{prob:.3f}\")"
      ],
      "id": "0B2qek-v-X9I"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00957de9cc184709a01368bc497e09ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02cbed4eaedb40ad972511cfcbbc0248": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd92956201547ba81b2bd57353c3fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4b4e88897841299a989c767c481684",
            "placeholder": "",
            "style": "IPY_MODEL_b7c811d669aa46949839eb002bbc0527",
            "value": " 780k/780k [00:00&lt;00:00, 950kB/s]"
          }
        },
        "1a8ffac0cf4340a5b9ca1d97b06284bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0397656ed84f6c8ae6fe993b0d4ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6c5b54662ee41bdac56de1566754506",
            "placeholder": "",
            "style": "IPY_MODEL_3ea541f4456142d2a185c63c995dd952",
            "value": "Downloading: 100%"
          }
        },
        "1cb8a256c12c46cbbf6e85fcc84cd771": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d28eb657bfd464bb724a9154b5364ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eedcf774c5745dbaf7bc2ca3fb79ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21fa5996e3924a9596c3e4cd5c67222e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bcbdf196c8f427ca3f52b721856b216",
              "IPY_MODEL_ad1a44ecca6f456485fe7a0564fbba06",
              "IPY_MODEL_b64dc1362b66403283c35ed1486d03ba"
            ],
            "layout": "IPY_MODEL_1a8ffac0cf4340a5b9ca1d97b06284bb"
          }
        },
        "2c7ffe282e5b45afa1817b94211e6e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90cb767246145a880f50970d92a490d",
            "placeholder": "",
            "style": "IPY_MODEL_00957de9cc184709a01368bc497e09ad",
            "value": "Downloading: 100%"
          }
        },
        "2cbbc3b940e042edb1c40804e68c8c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3283d6e30fd84386b242f93291c8cf19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9552a571893a4a398a0751f6a6ecd023",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b639053b79f14779a36791a8beae9f43",
            "value": 150
          }
        },
        "33501c1674444c2c82be30af6b0e7d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a84ffbc1c8974a5eb87fe481d4fe3a55",
            "max": 256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e85af90b09fa4ef1960873d231224c73",
            "value": 256
          }
        },
        "367fe5ad116447d0bbd52690cc967379": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c0f1582e9244ca92731edca6f15182",
            "max": 798293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df857a1953f14153af1e048c129debe4",
            "value": 798293
          }
        },
        "36816ad17f834690a2182f46ef077166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37b1389dc4ad4c09820a5a82a5e4cfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f54c8e32ae1a40a1b5ef335cdee602de",
              "IPY_MODEL_33501c1674444c2c82be30af6b0e7d6c",
              "IPY_MODEL_fc926dfcc0b54518a3848d889bdb0115"
            ],
            "layout": "IPY_MODEL_c41e9e9a625542a3826672040c8f67b2"
          }
        },
        "3867c2734aec4a2487c2ceb2550080b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ea541f4456142d2a185c63c995dd952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41c8df7396d7416887474be68c8677ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0bf9c30f354cf98762e45fe2f60eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4db418532e6f4559b77ee1e93441c435": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5030fd2ba5ac45b8970fa69307214296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cb8a256c12c46cbbf6e85fcc84cd771",
            "placeholder": "",
            "style": "IPY_MODEL_36816ad17f834690a2182f46ef077166",
            "value": " 687/687 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "56c0f1582e9244ca92731edca6f15182": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a189c79d1c84e6290136eadb5869d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b611c19012f41ad860a1277d7ebed2d",
            "max": 687,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a732e83c51d54bb198c8ea6198a160ae",
            "value": 687
          }
        },
        "5b611c19012f41ad860a1277d7ebed2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604ca22657b8441fa639d01ea6a1280d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ed9d5eb6844598b787f992b7b1d869": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f21d3a9b305e4443ac1f4048fc1e0542",
              "IPY_MODEL_367fe5ad116447d0bbd52690cc967379",
              "IPY_MODEL_0bd92956201547ba81b2bd57353c3fbe"
            ],
            "layout": "IPY_MODEL_4db418532e6f4559b77ee1e93441c435"
          }
        },
        "7528012daa0144119b1b5503bc67d1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9db1285fc8471ca4c8ce7726238fb1",
            "placeholder": "",
            "style": "IPY_MODEL_931f60229a234b7084cdff8ee64a172c",
            "value": " 150/150 [00:00&lt;00:00, 3.69kB/s]"
          }
        },
        "7bcbdf196c8f427ca3f52b721856b216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89696c9cf2ce40b59430a1c73416bbe9",
            "placeholder": "",
            "style": "IPY_MODEL_b7138a19e4ee4387a51b91a12adc6deb",
            "value": "Downloading: 100%"
          }
        },
        "83353edb1cd1455b80505f0e930bdaef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89696c9cf2ce40b59430a1c73416bbe9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd3e923bf7c43479ce9577cfccb2c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931f60229a234b7084cdff8ee64a172c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9489b9785f5d4413b67c26814d6c431c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948ae10118da4bb6968202f14024c804": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9552a571893a4a398a0751f6a6ecd023": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ca3303ff634644902c265c7979bdc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a3c5376f980483786b51ef772ff55b2",
              "IPY_MODEL_3283d6e30fd84386b242f93291c8cf19",
              "IPY_MODEL_7528012daa0144119b1b5503bc67d1d2"
            ],
            "layout": "IPY_MODEL_02cbed4eaedb40ad972511cfcbbc0248"
          }
        },
        "9a3c5376f980483786b51ef772ff55b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83353edb1cd1455b80505f0e930bdaef",
            "placeholder": "",
            "style": "IPY_MODEL_b65490f5a5434f5196f58dcfb74dfbe7",
            "value": "Downloading: 100%"
          }
        },
        "9e9db1285fc8471ca4c8ce7726238fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16c5be76a9148c086911e4fe144e25f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c5b54662ee41bdac56de1566754506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a732e83c51d54bb198c8ea6198a160ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a84ffbc1c8974a5eb87fe481d4fe3a55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1a44ecca6f456485fe7a0564fbba06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cbbc3b940e042edb1c40804e68c8c4a",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b0bf9c30f354cf98762e45fe2f60eca",
            "value": 456356
          }
        },
        "ad51b35e49404d4ba75e28a65e4149ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3a15d03a55c46b7851b2c9411be1e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d28eb657bfd464bb724a9154b5364ff",
            "max": 1421616707,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f96755f75c3e403b957f39e1bdba328e",
            "value": 1421616707
          }
        },
        "b639053b79f14779a36791a8beae9f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b64dc1362b66403283c35ed1486d03ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eedcf774c5745dbaf7bc2ca3fb79ed6",
            "placeholder": "",
            "style": "IPY_MODEL_d4f9e2eb5b1f4ab5a6f97175c0d72289",
            "value": " 446k/446k [00:00&lt;00:00, 927kB/s]"
          }
        },
        "b65490f5a5434f5196f58dcfb74dfbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7138a19e4ee4387a51b91a12adc6deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7c811d669aa46949839eb002bbc0527": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba5efd9a16284ca69cf9109e829ce4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c0397656ed84f6c8ae6fe993b0d4ab1",
              "IPY_MODEL_b3a15d03a55c46b7851b2c9411be1e9e",
              "IPY_MODEL_fa3ab5e902c549d68f6ea80525176274"
            ],
            "layout": "IPY_MODEL_41c8df7396d7416887474be68c8677ce"
          }
        },
        "c05f9ffaa0cd45d789ec4dc3f033f820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c7ffe282e5b45afa1817b94211e6e69",
              "IPY_MODEL_5a189c79d1c84e6290136eadb5869d50",
              "IPY_MODEL_5030fd2ba5ac45b8970fa69307214296"
            ],
            "layout": "IPY_MODEL_948ae10118da4bb6968202f14024c804"
          }
        },
        "c41e9e9a625542a3826672040c8f67b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90cb767246145a880f50970d92a490d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3df10a819e54a0dba06b710ccda97f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f9e2eb5b1f4ab5a6f97175c0d72289": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc17aad891ab4e209e0b843cceb15fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de4b4e88897841299a989c767c481684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df857a1953f14153af1e048c129debe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e85af90b09fa4ef1960873d231224c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f21d3a9b305e4443ac1f4048fc1e0542": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a16c5be76a9148c086911e4fe144e25f",
            "placeholder": "",
            "style": "IPY_MODEL_dc17aad891ab4e209e0b843cceb15fea",
            "value": "Downloading: 100%"
          }
        },
        "f54c8e32ae1a40a1b5ef335cdee602de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604ca22657b8441fa639d01ea6a1280d",
            "placeholder": "",
            "style": "IPY_MODEL_8fd3e923bf7c43479ce9577cfccb2c5b",
            "value": "Downloading: 100%"
          }
        },
        "f96755f75c3e403b957f39e1bdba328e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa3ab5e902c549d68f6ea80525176274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9489b9785f5d4413b67c26814d6c431c",
            "placeholder": "",
            "style": "IPY_MODEL_ad51b35e49404d4ba75e28a65e4149ec",
            "value": " 1.32G/1.32G [00:31&lt;00:00, 49.0MB/s]"
          }
        },
        "fc926dfcc0b54518a3848d889bdb0115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3df10a819e54a0dba06b710ccda97f2",
            "placeholder": "",
            "style": "IPY_MODEL_3867c2734aec4a2487c2ceb2550080b6",
            "value": " 256/256 [00:00&lt;00:00, 7.54kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}